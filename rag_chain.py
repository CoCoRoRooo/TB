import logging
import os
from dotenv import load_dotenv
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain.schema.runnable import RunnablePassthrough

from retriever import load_guides, load_posts, index_data_embeddings
from utils import format_documents, get_unique_union

logger = logging.getLogger(__name__)

# Variables globales pour stocker les chaÃ®nes de traitement
_retriever = None
_rag_chain = None
_generate_queries = None
_retrieval_chain = None


def get_retriever():
    """Retourne l'instance du retriever"""
    global _retriever
    return _retriever


def get_rag_chain():
    """Retourne l'instance de la chaÃ®ne RAG"""
    global _rag_chain
    return _rag_chain


def get_generate_queries():
    """Retourne l'instance de la chaÃ®ne de gÃ©nÃ©ration de requÃªtes"""
    global _generate_queries
    return _generate_queries


def get_retrieval_chain():
    """Retourne l'instance de la chaÃ®ne de rÃ©cupÃ©ration"""
    global _retrieval_chain
    return _retrieval_chain


def debug_context(context):
    print("=== CONTENU DU CONTEXT ===")
    print(context)
    print("==========================")
    return context


def initialize_rag_system():
    """Initialise le systÃ¨me RAG avec les chaÃ®nes de traitement"""
    global _retriever, _rag_chain, _generate_queries, _retrieval_chain

    logger.info("Initialisation du systÃ¨me RAG")

    # Charger les variables d'environnement
    load_dotenv()
    OPENAI_KEY = os.getenv("OPENAI_KEY")

    # Charger les donnÃ©es
    posts = load_posts("./data/techsupport_posts.json")
    guides = load_guides("./data/guides.json")

    # CrÃ©er le retriever
    _retriever = index_data_embeddings(posts, guides)

    # Le prompt pour le modÃ¨le
    final_prompt_template = PromptTemplate(
        input_variables=["context", "question"],
        template="""
L'utilisateur pose la question suivante :

â¡ï¸ {question}

Tu disposes uniquement des documents suivants : des guides techniques et des posts Reddit pertinents.
Ces contenus incluent des descriptions gÃ©nÃ©rales, des conseils pratiques, des solutions proposÃ©es par la communautÃ©, et parfois des instructions techniques dÃ©taillÃ©es.

ğŸ¯ Ta mission :

    Base strictement ta rÃ©ponse sur les informations prÃ©sentes dans les documents fournis ci-dessous ({context}).

    N'utilise aucune connaissance extÃ©rieure. Si une information nâ€™est pas prÃ©sente, indique-le explicitement.

    Fournis une rÃ©ponse structurÃ©e, professionnelle et en franÃ§ais.

ğŸ“š Sources disponibles :

{context}

ğŸ›  Format de rÃ©ponse attendu :

ğŸ” Analyse du problÃ¨me :

[PrÃ©sente une synthÃ¨se du problÃ¨me posÃ©, uniquement en te basant sur les documents.]

âœ… VÃ©rifications prÃ©alables recommandÃ©es :

[Liste les Ã©lÃ©ments Ã  inspecter ou tester avant toute manipulation, tels que suggÃ©rÃ©s dans les documents.]

ğŸ“ ProcÃ©dure dÃ©taillÃ©e proposÃ©e :

[Structure la procÃ©dure Ã©tape par Ã©tape : â€œÃ‰tape 1â€, â€œÃ‰tape 2â€â€¦ en tâ€™appuyant sur les guides ou les conseils Reddit.]

ğŸ’¡ Conseils ou prÃ©cautions Ã  prendre :

[Ajoute ici uniquement les recommandations explicitement mentionnÃ©es dans les documents.]

ğŸ”— Sources consultÃ©es :

[Liste les URL des documents (guides ou posts Reddit) utilisÃ©s pour construire la rÃ©ponse, selon les mÃ©tadonnÃ©es disponibles.]

ğŸ“Œ Important :
Tu dois strictement t'appuyer sur les contenus fournis dans {context}.
Aucune infÃ©rence ou ajout personnel nâ€™est autorisÃ©. Si la rÃ©ponse nâ€™est pas dÃ©ductible des documents, indique-le clairement.
""",
    )

    # Prompt pour gÃ©nÃ©rer des requÃªtes alternatives
    prompt_template = PromptTemplate(
        input_variables=["question"],
        template="""
Ta tÃ¢che est de gÃ©nÃ©rer cinq reformulations diffÃ©rentes de la question posÃ©e par l'utilisateur afin de retrouver des documents pertinents dans une base de donnÃ©es vectorielle.

En proposant plusieurs perspectives sur la question, ton objectif est d'aider l'utilisateur Ã  surmonter certaines limites de la recherche par similaritÃ© basÃ©e sur la distance.

Fournis ces questions alternatives, chacune sÃ©parÃ©e par un saut de ligne.

RÃ©pond en Anglais

Question initiale : {question}
""",
    )

    # Initialiser le LLM
    llm = ChatOpenAI(openai_api_key=OPENAI_KEY, model="gpt-4.1", temperature=0.0)

    # ChaÃ®ne de gÃ©nÃ©ration de requÃªtes
    _generate_queries = (
        prompt_template | llm | StrOutputParser() | (lambda x: x.split("\n"))
    )

    # ChaÃ®ne de rÃ©cupÃ©ration
    _retrieval_chain = _generate_queries | _retriever.map() | get_unique_union

    # ChaÃ®ne RAG complÃ¨te
    _rag_chain = (
        {
            "context": _retrieval_chain
            | format_documents
            | (lambda x: debug_context(x)),
            "question": RunnablePassthrough(),
        }
        | final_prompt_template
        | llm
        | StrOutputParser()
    )

    logger.info("SystÃ¨me RAG initialisÃ© avec succÃ¨s")
