import logging
import os
from dotenv import load_dotenv
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain.schema.runnable import RunnablePassthrough

from retriever import load_guides, load_posts, index_data_embeddings
from utils import format_documents, get_unique_union

logger = logging.getLogger(__name__)

# Variables globales pour stocker les chaÃ®nes de traitement
_retriever = None
_rag_chain = None
_generate_queries = None
_retrieval_chain = None


def get_retriever():
    """Retourne l'instance du retriever"""
    global _retriever
    return _retriever


def get_rag_chain():
    """Retourne l'instance de la chaÃ®ne RAG"""
    global _rag_chain
    return _rag_chain


def get_generate_queries():
    """Retourne l'instance de la chaÃ®ne de gÃ©nÃ©ration de requÃªtes"""
    global _generate_queries
    return _generate_queries


def get_retrieval_chain():
    """Retourne l'instance de la chaÃ®ne de rÃ©cupÃ©ration"""
    global _retrieval_chain
    return _retrieval_chain


def initialize_rag_system():
    """Initialise le systÃ¨me RAG avec les chaÃ®nes de traitement"""
    global _retriever, _rag_chain, _generate_queries, _retrieval_chain

    logger.info("Initialisation du systÃ¨me RAG")

    # Charger les variables d'environnement
    load_dotenv()
    OPENAI_KEY = os.getenv("OPENAI_KEY")

    # Charger les donnÃ©es
    posts = load_posts("./data/techsupport_posts.json")
    guides = load_guides("./data/guides.json")

    # CrÃ©er le retriever
    _retriever = index_data_embeddings(posts, guides)

    # Le prompt pour le modÃ¨le
    final_prompt_template = PromptTemplate(
        input_variables=["context", "question"],
        template="""
L'utilisateur pose la question suivante :

â¡ï¸ {question}

Tu disposes ci-dessous de guides techniques et de posts Reddit pertinents. Ces contenus incluent des descriptions gÃ©nÃ©rales, des conseils pratiques, des solutions proposÃ©es par la communautÃ©, et parfois des instructions techniques dÃ©taillÃ©es.

ğŸ¯ Ta mission :

- Analyse et synthÃ©tise les informations issues des guides techniques et des posts Reddit pour rÃ©pondre Ã  la question.

- Fournis une rÃ©ponse structurÃ©e et complÃ¨te.

- Utilise les Ã©tapes dÃ©crites dans les guides techniques, si prÃ©sentes, et les solutions suggÃ©rÃ©es par les utilisateurs dans les posts Reddit.

- RÃ©pond en FranÃ§ais

ğŸ“š Sources disponibles :

{context}

ğŸ›  Format de rÃ©ponse attendu :

---

ğŸ” Analyse du problÃ¨me :

[PrÃ©sente une synthÃ¨se du problÃ¨me posÃ©, en te basant sur les informations extraites des documents.]

âœ… VÃ©rifications prÃ©alables recommandÃ©es :

[Liste les Ã©lÃ©ments Ã  inspecter ou tester avant de commencer les manipulations.]

ğŸ“ ProcÃ©dure dÃ©taillÃ©e proposÃ©e :

[Utilise les Ã©tapes comme "Step 1", "Step 2" pour les guides iFixit, ou les conseils donnÃ©s dans les posts Reddit.]

ğŸ’¡ Conseils supplÃ©mentaires ou prÃ©cautions Ã  prendre :

[Ajoute des conseils supplÃ©mentaires tirÃ©s des guides ou des commentaires des utilisateurs.]

ğŸ”— Sources consultÃ©es :

[Indique ici les URL des documents (guides ou posts Reddit) ayant servi Ã  construire ta rÃ©ponse. Utilise les URLs disponibles dans les mÃ©tadonnÃ©es des documents fournis.]

---

ğŸ¯ Important : Structure ta rÃ©ponse de maniÃ¨re fluide, concise, et professionnelle. Mentionne les sources utilisÃ©es, telles que l'URL du guide ou du post Reddit.
""",
    )

    # Prompt pour gÃ©nÃ©rer des requÃªtes alternatives
    prompt_template = PromptTemplate(
        input_variables=["question"],
        template="""
Ta tÃ¢che est de gÃ©nÃ©rer cinq reformulations diffÃ©rentes de la question posÃ©e par l'utilisateur afin de retrouver des documents pertinents dans une base de donnÃ©es vectorielle.

En proposant plusieurs perspectives sur la question, ton objectif est d'aider l'utilisateur Ã  surmonter certaines limites de la recherche par similaritÃ© basÃ©e sur la distance.

Fournis ces questions alternatives, chacune sÃ©parÃ©e par un saut de ligne.

RÃ©pond en Anglais

Question initiale : {question}
""",
    )

    # Initialiser le LLM
    llm = ChatOpenAI(openai_api_key=OPENAI_KEY, model="gpt-4.1", temperature=0.5)

    # ChaÃ®ne de gÃ©nÃ©ration de requÃªtes
    _generate_queries = (
        prompt_template | llm | StrOutputParser() | (lambda x: x.split("\n"))
    )

    # ChaÃ®ne de rÃ©cupÃ©ration
    _retrieval_chain = _generate_queries | _retriever.map() | get_unique_union

    # ChaÃ®ne RAG complÃ¨te
    _rag_chain = (
        {
            "context": _retrieval_chain,
            "question": RunnablePassthrough(),
        }
        | final_prompt_template
        | llm
        | StrOutputParser()
    )

    logger.info("SystÃ¨me RAG initialisÃ© avec succÃ¨s")
