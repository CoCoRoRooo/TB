# üöÄ Assistant Technique avec IA et Recherche de Guides

Ce projet est une **API Flask** avec une **interface web** qui permet aux utilisateurs de poser des questions techniques. Le syst√®me utilise :

- **FAISS** pour la recherche vectorielle des guides les plus pertinents
- **Mistral (via Ollama) ou OpenAI GPT-4** pour g√©n√©rer des r√©ponses intelligentes
- **Flask** pour g√©rer l'API et la communication
- **LangChain** pour orchestrer la cha√Æne de traitement RAG

---

## üìÅ Structure des fichiers

```
üìÇ TB
‚îÇ-- üìÇ static/               # Fichiers CSS pour le style
‚îÇ   ‚îú‚îÄ‚îÄ styles.css          # Feuille de style principale
‚îÇ-- üìÇ templates/            # Fichiers HTML
‚îÇ   ‚îú‚îÄ‚îÄ index.html          # Interface utilisateur
‚îÇ-- üìÇ data/                 # Fichiers de donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ guides.json         # Base de connaissances (guides techniques)
‚îÇ   ‚îú‚îÄ‚îÄ guides.py           # R√©cup√©ration et stockage des guides depuis iFixIt
‚îÇ-- .env                    # Stocke la cl√© API OpenAI
‚îÇ-- app.py                  # API Flask
‚îÇ-- tokenizer.py            # Gestion de l'indexation FAISS
‚îÇ-- llm.py                  # G√©n√©ration de r√©ponses avec Mistral/OpenAI
‚îÇ-- README.md               # Documentation du projet
```

---

## üõ†Ô∏è Installation et ex√©cution

### 1Ô∏è‚É£ Pr√©requis

- **Python 3.8+**
- **Cl√© API OpenAI** (si utilisation de GPT-4, √† ajouter dans `.env`)
- **Ollama** install√© pour utiliser Mistral en local

### 2Ô∏è‚É£ Installation des d√©pendances

```bash
pip install -r requirements.txt
```

#### Explication des d√©pendances :

- **flask** ‚Üí Pour cr√©er l'API backend qui communique avec l'interface web.
- **python-dotenv** ‚Üí Pour charger des variables d'environnement depuis un fichier .env de mani√®re s√©curis√©e.
- **langchain** ‚Üí Pour orchestrer la cha√Æne RAG avec retrieval et LLM.
- **ollama** ‚Üí Pour ex√©cuter Mistral localement.
- **langchain_community** ‚Üí Module compl√©mentaire pour LangChain.
- **langchain_openai** ‚Üí Pour interagir avec l'API OpenAI et g√©n√©rer des r√©ponses via ChatGPT.

### 3Ô∏è‚É£ Lancement du serveur Flask

```bash
python app.py
```

Le serveur tournera sur `http://127.0.0.1:5000/`

---

## üìù Explication des fichiers

### **1Ô∏è‚É£ `tokenizer.py`** (Indexation des guides avec FAISS)

Ce fichier :

- Charge un fichier JSON contenant des guides techniques
- Convertit les guides en **vecteurs** avec `HuggingFaceEmbeddings`
- Cr√©e une **base FAISS** pour la recherche rapide

Extrait de code :

```python
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-MiniLM-L6-v2")
vector_store = FAISS.from_documents(documents, embedding_model)
retriever = vector_store.as_retriever()
```

---

### **2Ô∏è‚É£ `llm.py`** (G√©n√©ration de r√©ponses avec GPT-4 ou Mistral via Ollama)

Ce fichier :

- Charge les guides index√©s
- Trouve les guides les plus pertinents via FAISS
- G√©n√®re une r√©ponse avec **GPT-4 ou Mistral**
- Utilise **LangChain** pour structurer le processus

Extrait de code :

```python
class OllamaLLM(LLM):
    model: str = "mistral"

    def _call(self, prompt: str, stop: List[str] = None) -> str:
        response = ollama.chat(model=self.model, messages=[{"role": "user", "content": prompt}])
        return response["message"]["content"]
```

On peut choisir le mod√®le utilis√© en modifiant cette ligne :

```python
use_ollama = True  # Mettre √† False pour utiliser OpenAI
```

---

### **3Ô∏è‚É£ `app.py`** (API Flask)

Ce fichier :

- Expose une API `POST /ask` qui prend une question et renvoie une r√©ponse
- Charge FAISS et le mod√®le de g√©n√©ration

Extrait de code :

```python
@app.route("/ask", methods=["POST"])
def ask():
    data = request.json
    user_query = data.get("query", "")

    if not user_query:
        return jsonify({"error": "Aucune question fournie"}), 400

    response = rag_chain.invoke(user_query)
    return jsonify({"query": user_query, "response": response})
```

---

### **4Ô∏è‚É£ `index.html`** (Interface utilisateur)

Une page HTML stylis√©e qui permet de poser des questions via un champ de saisie et un bouton.

---

## üî• Exemples d'utilisation

1Ô∏è‚É£ **Poser une question**

```json
POST /ask
{
    "query": "Mon iPhone ne charge plus"
}
```

2Ô∏è‚É£ **R√©ponse du chatbot**

```json
{
  "response": "Essayez d'utiliser un autre c√¢ble et v√©rifiez le port Lightning."
}
```

---

## üéØ Am√©liorations possibles

- ‚úÖ Supporter d'autres mod√®les d'IA (Llama, Claude...)
- ‚úÖ Ajouter un syst√®me d'historique des questions
- ‚úÖ Interface utilisateur encore plus interactive

üöÄ **Projet cl√© en main pour un assistant technique intelligent !**
